---
title: "May analysis (tbc)"
author: "BeDataDriven"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this monthly report, we deep down more advance analyses.

#### Identify the distribution

It is a good practice to find the "distribution" because it can give us a nice set of tools to apply on the data. There're several questions to do before analyze? 

Is the data normally distributed? How to find it? Plot each of the points in the raw data, then one can visually see the distribution of the word count measure.

Finding the distribution is important. If we can understand the distribution, then it's possible to distribute single information products based on single variables e.g. a bar chart word count per partner. However, this can be achieved towards the end of the project after all being sure about the test analyses being done.

## Textual data processing

Perform stemming, which you bring nouns/verbs back to infinitive forms, and tokenization, which is separating words in meaningful pieces.

Remove noise in the text. There are usually a list of such words for each language and they are called as stop-words as they are overly distributed in the text and they will not give so meaningful results itself. Stop-words are including articles (*el/la*), conjunctions (*y*), pronouns (*yo/t√∫/etc.*) and so on.

---

When the data is not normally distributed, looking at the median can give more insights than looking at the mean.

We shouldn't look at average because average is very sensitive to outliers. For instance, when a response from a partner receives a long text than usual, that will skew the mean score therefore we will not be able to understand the reason.
