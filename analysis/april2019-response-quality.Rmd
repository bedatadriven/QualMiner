---
title: "Response quality"
author: "Metin Yazici, BeDataDriven"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
## Libraries
library(dplyr)
library(tidyr)
library(ggplot2)
## functions
source(file.path("..", "R", "analysis-methods.R"))
## Pre-set the bw theme for ggplot (for plots don't use any custom theme).
ggplot2::theme_set(ggplot2::theme_bw())
## knitr options
knitr::opts_chunk$set(echo = TRUE, paged.print = FALSE)
```

## Introduction

*RQs:* What is the quality of textual responses in the narrative fields?

- Do responses with a larger word count have more quality than the responses with less word count?

- What is the distribution between response word count and explanatory variables such as question, form topic, canton name, partner name etc.

- Is there any relationship between the word count of responses and question word count?

The strive is to find if any relation exists and, as a result, see which responses worked and which did not work.

## Data import & preparation

Read the data from source that has been extracted, cleaned and transformed:

```{r data}
source(file.path("..", "R", "/global-header.R"))
## read data from disk:
form.table <- jsonlite::fromJSON(file.path("..", TEXT.DATA.PATH))
```

Select the rows where the field type equals to `NARRATIVE`, which indicates that is a multi-line text field in the *ActivityInfo*. Select these columns and analyze them by comparing and contrasting with other fields types associated to the textual field types.

```{r}
## order matters for display purposes:
col.names <- c(
  "labelFolder",
  "labelForms",
  "Month",
  "question",
  "response",
  "description",
  "partnerName",
  "cantonName",
  "cantonParentName",
  "id",
  "recordId"
)
## if we choose a column name by mistake:
stopifnot(!anyDuplicated(col.names) > 0)
compact <- subset(
  x = form.table, 
  subset = !is.na(form.table$response) & type == "NARRATIVE", 
  select = col.names
)
```

## Analysis

One issue with the nature of the questions is that they are only unique in a
form. These questions can be distributed across multiple forms. The questions
sharing the same name will have different meanings. For instance, the question
"*Cualitativo*" from the form "*Salud*" should imply different thing than the
question "*Cualitativo*" from the form "*Protección_VBG*".

In order to solve this kind of problem:

+ We can merge question with the form and also its folder label. There we can
achieve a unique name for each question.

+ Another thing to resolve this would be doing analysis to move the analysis up
to form level. In this file, we did both, therefore the analysis shown as below:

Count of responses per topic/question:
```{r}
cp <- compact %>%
  mutate(.responseWordCount = word_count(response)) %>%
  mutate(.questionWordCount = word_count(question)) %>%
  group_by(labelForms) %>%
  select(
    labelForms, question, response, 
    .responseWordCount, .questionWordCount, 
    partnerName, cantonName,
    description
  )
head(cp)
```

It's also a good practice to see the number of questions. For example, one question has two responses, therefore they're short. Therefore, jittered points are added to give a glance about the number of observations in the same plot.

We recode form topics as they are too long and clutters the plots. This can be
called the **recode table** to look up form labels:
```{r}
## make the label forms factor for recoding:
cp$labelFormsRecode <- as.factor(cp$labelForms)
recode.lvls <- sapply(seq_along(unique(cp$labelFormsRecode)), function(x) paste0("F", x))
levels(cp$labelFormsRecode) <- recode.lvls

recode_tbl <- cp %>% 
  arrange(labelFormsRecode) %>% 
  select(labelFormsRecode, labelForms) %>% 
  distinct()

knitr::kable(recode_tbl)
```

Box plot form topics and response word counts (based on raw data):
```{r}
cp %>%
  gather(variable, value, .responseWordCount, .questionWordCount) %>%
  ggplot(aes(labelFormsRecode, value, fill = variable)) +
  geom_boxplot(outlier.colour = "orange", outlier.shape = 1, outlier.alpha = 0.35) +
  coord_flip() +
  geom_jitter(alpha = 0.35) +
  labs(
    title = "Response and Question word counts per form topic",
    subtitle = "A box plot distribution",
    caption = "*Please refer to recode table for label forms"
  ) +
  theme_ecuador1()
```

The response word count distribution per form topic categorized by partner name:
```{r}
cp %>%
  gather(variable, value, .responseWordCount) %>% 
  ggplot(aes(labelFormsRecode, value)) +
  geom_boxplot(outlier.colour = "orange", outlier.shape = 1, outlier.alpha = 0.35) +
  coord_flip() +
  geom_jitter(alpha = 0.35) +
  facet_wrap(partnerName ~ ., scales = "free") +
  labs(
    title = "Word count of responses by form topics per partner",
    subtitle = "A box plot distribution",
    caption = "*Please refer to recode table for label forms"
  ) +
  theme_ecuador1()
```

In the plots above, the outliers are shown in orange color. Outliers are the points placed outside the whiskers, which is the long line, of the boxplot[^1].

The response word count distribution per form topic categorized by canton name:
```{r}
cp %>%
  gather(variable, value, .responseWordCount) %>% 
  ggplot(aes(labelFormsRecode, value)) +
  geom_boxplot(outlier.colour = "orange", outlier.shape = 1, outlier.alpha = 0.35) +
  coord_flip() +
  geom_jitter(alpha = 0.35) +
  facet_wrap(cantonName ~ ., scales = "free") +
  labs(
    title = "Word count of responses by form topics per canton",
    subtitle = "A box plot distribution",
    caption = "*Please refer to recode table for label forms"
  ) +
  theme_ecuador1()
```

A caveat:
Reducing multiple values down to a single value should be avoided in the early stages of the analysis because reducing hides a lot e.g. a bar chart showing average the word count per partner. Some partners may write longer than others, because:

1. They *really* write longer than other partners.

2. The questions they answered require short answers.

### The "Description" field

Some questions have the description field giving extra details about the questions.

Do some questions with the extra description field have better *response quality* than the questions which does not have it?

Looking at the table containing form name, question, description and so on:

```{r}
dsp <- cp %>% 
  mutate(.hasDescription = ifelse(is.na(description), FALSE, TRUE)) %>% 
  mutate(.descriptionWordCount = word_count(description)) %>%
  select(labelForms, labelFormsRecode, 
         .responseWordCount, .questionWordCount, .descriptionWordCount, 
         .hasDescription)
```

We see in the plot below that the response word counts per form and colored if a
response has a description field or not. Having a description field or not is
calculated as that a description field has minimum one word.
The responses with the longest word
counts are the ones with description. Nevertheless, it is not so easy to see a
clear trend that there's a correlation between response word count and
description fields. Interesingly, the form *F15*, which is *Protección_VBG*, has
no description fields at all.
```{r}
dsp %>% 
  ggplot(aes(.responseWordCount, labelFormsRecode, color = .hasDescription)) +
  geom_point() +
  theme_ecuador1()
```

We look below the description word count, and compare with the
response word count (and remove the categorical field displaying if the question
of a response has a description field).

### The regression line

We can look multiple continuous variables in our data.

- word count of response field: the dependent variable.

- word count of question field: an independent variable.

- word count of description field: an independent variable.

Scatter plots help understand the characteristics of those variables.
However, we miss a general understanding that is the *trend line*.
We apply linear and LOESS regressions to look see the trend if longer question
and description fields result to longer responses.
```{r}
p1 <- dsp %>% 
  ggplot(aes(x = .responseWordCount, y = .questionWordCount)) +
  geom_jitter(alpha = 0.35) +
  geom_smooth(aes(colour = "linear"), method = "lm") +
  geom_smooth(aes(colour = "LOESS"), method = "loess") +
  scale_colour_manual(name = "Regression", values = c("blue", "red")) +
  theme_ecuador1() +
  theme(legend.position = "bottom")
p2 <- dsp %>% 
  ggplot(aes(x = .responseWordCount, y = .descriptionWordCount)) +
  geom_jitter(alpha = 0.35) +
  geom_smooth(aes(colour = "linear"), method = "lm") +
  geom_smooth(aes(colour = "LOESS"), method = "loess") +
  scale_colour_manual(name = "Regression", values = c("blue", "red")) +
  theme_ecuador1() +
  theme(legend.position = "bottom")
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

The gray area around the lines shows the confidence band at the 0.95 level.
Although there's a some straight slope in the linear regression line, we cannot
say that the trend line is robust because the confidence band representing the
uncertainty in the estimate is wide.

## Conclusion

On the whole, we assumed that *the more is better*. The limitations, as
described above, are based on the unequal distribution of the data. The word
count of responses and questions can be related to other things, such as the
questions require short answers so then the responses tend to be shorter.

Additionally, we can have a cross-analysis to test these outcomes. It might be a
good idea to have a small subset of data and ask an expert to test the
assumptions qualitatively. For instance, we can take the first twenty reponses
with the highest word count and the last twenty responses with the lowest word
count. We chose the extreme directions because they point out the greatest
differences which are easier to test assumptions.
