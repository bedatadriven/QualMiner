---
title: "QualMiner: Exploring qualitative indicators via text mining methods"
author: "Metin Yazici <i>(BeDataDriven B.V.)</i>, Alexander Bertram <i>(BeDataDriven B.V.)</i>"
date: "`r Sys.Date()`"
output:
  html_document:
    includes:
      in_header: assets/header.html
      after_body: assets/footer.html
    theme: cosmo
    css: assets/style.css
    highlight: pygments
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

<script src="assets/script.js"></script>

```{r setup, include=FALSE}
knitr::clean_cache()
## Header file
source(file.path("..", "R", "global-header.R"))
## Analysis related calls
source(file.path("..", "R", "analysis-methods.R"))
source(file.path("..", "R", "analysis-helpers.R"))
## Libraries
library(tidyverse)
library(tidytext)
library(tsibble)
library(scales)
library(treemapify)
library(gt)
## Pre-set the bw theme for ggplot (for plots don't use any custom theme).
ggplot2::theme_set(ggplot2::theme_bw())
## knitr options
knitr::opts_chunk$set(echo = FALSE, paged.print = FALSE, cache = TRUE)
## read Data from disk:
form.table <- jsonlite::fromJSON(file.path("..", TEXT.DATA.PATH))
## (force it to be a tibble):
form.table <- tibble::as_tibble(form.table)
```

# Introduction

```{r child = 'analysis/introduction.Rmd', eval=TRUE}
```

# Data preparation

The data has been extracted from *ActivityInfo* and pre-processed to make it
ready for the analysis. Check the calls in the `R/` directory of the project
repository to see how the process went on.

### Data import & preparation

Read the data from the source that has been extracted, cleaned, and transformed.
Select the rows where the field type equals to `NARRATIVE`, this indicates that
is a multi-line text field in *ActivityInfo*. Select these columns and
analyze them by comparing and contrasting with other fields types associated with
the textual field types.

```{r, include=FALSE}
## unique record ids
unique(form.table$recordId)

## record ids and unique fields
form.table %>% 
  group_by(recordId) %>% 
  summarize(len = length(recordId)) %>% 
  arrange(desc(len))

## Code names per record
code.nms <- form.table %>% group_by(recordId) %>% select(recordId, code) %>% 
  summarize(names = list(code))
head(code.nms$names)

## Do all records have "Socio" field?
socio.fields <- sapply(seq_along(code.nms$names), function(i) "Socio" %in% code.nms$names[[i]])
all(socio.fields)

## Do all records have "direct_indirect" field?
direct_indirect.fields <- sapply(seq_along(code.nms$names), function(i) "direct_indirect" %in% code.nms$names[[i]])
all(direct_indirect.fields)
```

```{r}
partners <- form.table %>% 
  group_by(recordId) %>% 
  filter(code == "Socio") %>% 
  mutate(response = if_else(response == "FALSE", NA_character_, response)) %>% # recode FALSE
  select(recordId, partnerName, response, canton, province) %>% 
  rename(subPartnerName = response) %>% 
  mutate(subPartnerName = if_else(is.na(subPartnerName), partnerName, subPartnerName))
```

```{r}
p <- partners %>% 
  group_by(partnerName) %>% 
  count(partnerName, sort=TRUE) %>% 
  ungroup() %>% 
  mutate(prop = round(n/sum(n), 3)) %>% 
  mutate(freq = paste0(round(100 * n/sum(n), 0), "%"))
p %>% knitr::kable()
```

The table above shows partner count per each record:

+ **`r p[1,"partnerName",drop=T]`** has most of the records with
a frequency of *`r p[1,"freq",drop=T]`*.

+ Second, **`r p[2,"partnerName",drop=T]`** comes with a frequency of 
*`r p[2,"freq",drop=T]`*. 
The frequency difference between the partners **`r p[1,"partnerName",drop=T]`** and
**`r p[2,"partnerName",drop=T]`** is 
*`r paste0(floor(convolve((p[1,"prop",drop=T]-p[2,"prop",drop=T]), 100)), '%')`*.

```{r}
psb <- partners %>% 
  group_by(subPartnerName) %>% 
  count(subPartnerName, sort=TRUE) %>% 
  drop_na() %>% 
  ungroup() %>% 
  mutate(prop = round(n/sum(n), 3)) %>% 
  mutate(freq = paste0(round(100 * n/sum(n), 0), "%"))
psb %>% knitr::kable()
```

The table above shows sub-partner count per each record.

+ The sub-partner reporting the most is **`r psb[1,"subPartnerName",drop=T]`**, 
which is by *`r psb[1,"freq",drop=T]`*.

+ The rest of the sub-partners have small numbers in the responses, however,
they might be reporting much with their partners. We will see this in the next
plot.

```{r ppsb-for-text-template, echo=FALSE}
PartnerSubProp <- partners %>% 
  group_by(partnerName, subPartnerName) %>% 
  count(partnerName, subPartnerName, sort=TRUE) %>% 
  summarize(n = sum(n)) %>% 
  mutate(prop = round(n/sum(n), 3)) %>% 
  mutate(freq = paste0(floor(100 * n/sum(n)), "%"))
acnur.hias.part <- PartnerSubProp %>% filter(partnerName %in% "ACNUR", subPartnerName %in% "HIAS")
```

The plots placed in the tabs below show the proportion of records entered by
sub-partners and partners.

+ *`r acnur.hias.part[,"n",drop=T]`* out of 
*`r sum(PartnerSubProp %>% filter(partnerName %in% "ACNUR") %>% pull(n))`* 
total responses of **ACNUR** is actually coming from **HIAS**.

+ **UNICEF** has more diversed partners in terms of reporting.
*`r PartnerSubProp%>%filter(partnerName%in% "UNICEF", subPartnerName %in% "HIAS") %>% pull(freq)`*
of responses of **UNICEF** comes from **HIAS**.
*`r PartnerSubProp%>%filter(partnerName %in% "UNICEF", subPartnerName %in% "UNICEF") %>% pull(freq)`*
of reporting comes from the **UNICEF** itself.

+ The most diversed partner is **PMA**. There are 
*`r nrow(PartnerSubProp %>% filter(partnerName %in% "PMA"))`* partners reporting. 
**HIAS** reports
*`r PartnerSubProp %>% filter(partnerName %in% "PMA", subPartnerName %in% "HIAS") %>% pull("freq")`* of the records.

Those are the total numbers of reporting, not specific to the narratives. In the next section, we count the number of reportings done in the narrative sections.

```{r child = 'analysis/tabset-partner.Rmd', eval=TRUE}
```

## Narrative data

```{r data-source-preparation}
col.names <- c(
  "labelFolder",
  "labelForms",
  "Month",
  "question",
  "response",
  "description",
  "partnerName",
  "subPartnerName",
  "province",
  "canton"
)
narratives <- form.table %>%
  filter(!is.na(response) & type == "NARRATIVE") %>%
  inner_join(
    select(partners, recordId, partnerName, subPartnerName),
    by = c("partnerName", "recordId")
  ) %>%
  select(col.names)
```

### The number of partners and sub-partners recording narrative data

```{r}
narratives_part_count <- narratives %>% 
  group_by(partnerName, subPartnerName) %>% 
  count(partnerName, subPartnerName, sort=TRUE) %>% 
  summarize(n = sum(n)) %>% 
  mutate(prop = round(n/sum(n), 3)) %>% 
  mutate(freq = paste0(floor(100 * n/sum(n)), "%"))
```

Not all partners (and sub-partners) enter narrative records.

```{r, warning=FALSE, fig.width=8, fig.height=8}
## grouped facet wraps. Source: https://stackoverflow.com/questions/14840542/place-a-legend-for-each-facet-wrap-grid-in-ggplot2
plot_partners_splitted <- split(narratives_part_count, f = narratives_part_count$partnerName)
plot_partners_splitted_front <- plot_partners_splitted[c(c("ACNUR", "UNICEF"), setdiff(names(plot_partners_splitted), c("ACNUR", "UNICEF")))] 
plot_partners_list <- lapply(seq_along(plot_partners_splitted_front), function(i) {
  ggplot(plot_partners_splitted_front[[i]], aes(x = partnerName, y = prop)) +
    geom_bar(aes(fill = reorder(subPartnerName,-prop)), position = "dodge", stat =
               "identity", color = "black") +
    facet_wrap(~ partnerName, scales = "fixed") +
    geom_label(
      aes(
        label = freq,
        group = reorder(subPartnerName,-prop),
        vjust = 0.65
      ),
      position = position_dodge(width = 1),
      label.size = 0.35
    ) +
    xlab(NULL) +
    ylab(NULL) +
    theme_ecuador1() +
    theme(
      axis.text.x = element_blank(),
      axis.ticks.x = element_blank(),
      legend.title = element_blank(),
      legend.position = "bottom"
    ) +
    scale_fill_brewer(palette = "Set2")
})
# "cowplot" is really civilized version of 'gridExtra'
do.call(cowplot::plot_grid, plot_partners_list)
```

***

### The number cantons and provinces recording narrative data

```{r}
locations <- 
  narratives %>% 
  count(province, canton) %>%
  group_by(province, canton) %>% 
  summarize(n = sum(n)) %>%
  mutate(canton.prop = round(n/sum(n), 3)) %>% 
  mutate(canton.freq = paste0(floor(100 * n/sum(n)), "%")) %>% 
  ungroup() %>% 
  mutate(province.prop = round(n/sum(n), 3)) %>% 
  mutate(province.freq = paste0(floor(100 * n/sum(n)), "%")) %>% 
  arrange(desc(n))
```

The table is alphabetically ordered.
```{r canton-locations-tbl}
locations.tbl <- locations %>%
  arrange(province, desc(n))
rl <- rle(locations.tbl$province)$lengths
res <- c()
for (r in rl) {
  if (r == 1) {
    res <- c(res, TRUE)
  } else {
    res <- c(res, c(TRUE, rep(FALSE, r-1)))
  }
}
locations.tbl <- cbind(locations.tbl, res)
for (i in seq_along(locations.tbl$res)) {
  if (!locations.tbl$res[i]) {
    locations.tbl$province[i] <- ""
  }
}
locations.tbl %>%
  as_tibble() %>%
  select(province, canton, n, province.prop, province.freq) %>%
  gt() %>% 
  tab_options(
    row.striping.include_table_body = FALSE,
    row.striping.include_stub = TRUE
  )
```

Treemap plot showing canton and province reporting frequencies.

```{r}
tree.colors <-c(
  RColorBrewer::brewer.pal(name = "Dark2", n = 8),
  RColorBrewer::brewer.pal(name = "Set2", n = 8)
)

ggplot(locations,
       aes(
         area = province.prop,
         fill = province,
         #label = sprintf("%s (%s)", canton, canton.freq),
         label = canton,
         subgroup = sprintf("%s\n(%s)", province, province.freq)
       )) +
  geom_treemap()+
  geom_treemap_subgroup_border(color="gray25")+
  geom_treemap_text(colour = "black", place = "centre", alpha = 0.45, reflow = TRUE, min.size = 0)+
  geom_treemap_subgroup_text(grow = TRUE, colour="white", alpha = 0.85, place = "topleft", fontface = "italic")+
  theme(legend.position = "none") +
  scale_fill_manual(values = tree.colors)
```

`r knitr::knit_exit()`

# Analysis

## Label forms recode table

First of all, we shorten the names and therefore re code form topics because they appear to be
too long and disarray the plots. The *re coded table* below provides a  look up
for form labels and their abbreviations:

```{r recode-table}
## only recode some long label forms, shorter names can stay as it is (e.g.
## `Salud`)
narratives <- narratives %>% 
  mutate(
    labelFormsRecode = recode(
      labelForms,
      "Alojamiento Temporal" = "Alojamiento",
      "Necesidades básicas/Otro" = "Necesidades",
      "Manejo de la información y entrega directa de la información a la población" = "Población",
      "Manejo de la información para socios y análisis de las necesidades" = "Socios",
      "Protección_VBG" = "VBG",
      "Trata_y_tráfico" = "Tráfico",
      "Acceso_a_educación" = "Educación",
      "Acceso a vivienda y hábitat dignos en comunidades receptoras" = "Hábitat",
      "Medios de vida y formación técnico-profesional" = "Técnico",
      "Cohesión_social" = "SocialCohesión",
      "Apoyo Educacional a Comunidades Receptoras" = "Educacional",
      "Asistencia técnica para VBG-SSR" = "VBG_SSR",
      "Asistencia técnica para protección/gestión de fronteras" = "Fronteras",
      "Asistencia técnica para gestion de la informacion y coordinacion" = "Coordinacion",
      "Asistencia técnica para el sector laboral" = "SectorLaboral",
      "Asistencia técnica para protección" = "Protección",
      "Asistencia técnica para protección de la infancia" = "ProtecciónInfancia",
      "Protección_LGBTI" = "LGBTI"
    )
  )

recode_tbl <- narratives %>% select(labelFormsRecode, labelForms) %>% distinct()
knitr::kable(cbind("i" = seq(nrow(recode_tbl)), recode_tbl))
```

## Response quality

Response quality means how much response the questions receive. The idea is to
find relations that affect the response quality to understand if they work or
not under some conditions.

*Research questions:*

+ What is the quality of textual responses in the narrative fields?

+ Is there any relationship between the word counts of response, question and
description fields?

+ What is the distribution between response word count and explanatory variables
such as the question, form topic, canton name, partner name, etc.

*Assumptions:*

+ Responses with a *larger word count* have more quality than the responses
with *smaller word count*.

In other words, we assume that *the more word the better is*. The limitations
are based on the unequal distribution of the data. The word count of responses
and questions can be related to other things, such as the questions require
short answers so then the responses tend to be shorter.

Additionally, we can have a cross-analysis to test these outcomes. It might be a
good idea to have a small subset of data and ask an expert to test the
assumptions qualitatively. For instance, we can take the first twenty responses
with the highest word count and the last twenty responses with the lowest word
count. We chose the extreme directions because they point out the greatest
differences which are easier to test assumptions.

### Word count 

One issue with the nature of the questions is that they are only unique in a
form. These questions can be distributed across multiple forms. The questions
sharing the same name will have different meanings. For instance, the question
"*Cualitativo*" from the form "*Salud*" should imply different thing than the
question "*Cualitativo*" from the form "*Protección_VBG*".

In order to solve this kind of problem:

+ We can combine question with the form and also its folder label. There we can
achieve a unique name for each question.

+ Another thing to resolve this would be doing analysis to move the analysis up
to form level. In this file, we did both, therefore the analysis shown as below:

Count of responses per topic/question:
```{r count-response}
narratives.wc <- narratives %>%
  mutate(.responseWordCount = word_count(response)) %>%
  mutate(.questionWordCount = word_count(question)) %>%
  group_by(labelForms) %>%
  select(
    labelForms, question, response, 
    .responseWordCount, .questionWordCount, 
    partnerName, canton,
    description, labelFormsRecode
  ) %>% 
  ungroup()
kable_truncate(
  head(narratives.wc),
  c("labelForms", "question", "response", "description"),
  trunc.level = 10
)
```

It's also a good practice to see the number of questions. For example, one
question has two responses, therefore they're short. Therefore, jittered points
are added to give a glance about the number of observations in the same plot.

```{r plot-topic-response-wc, fig.cap="Figure: Box plot form topics and response word counts based on the raw data"}
narratives.wc %>%
  gather(variable, value, .responseWordCount, .questionWordCount) %>%
  ggplot(aes(labelFormsRecode, value, fill = variable)) +
  geom_boxplot(outlier.colour = "orange", outlier.shape = 1, outlier.alpha = 0.35) +
  coord_flip() +
  geom_jitter(alpha = 0.35) +
  labs(
    title = "Response and Question word counts per form topic",
    subtitle = "A box plot distribution",
    caption = "*Please refer to recode table for label forms"
  ) +
  theme_ecuador1() +
  theme(legend.position = "bottom")
```

In the plot above, the outliers are shown in orange color. Outliers are the
points placed outside the whiskers, which is the long line, of the boxplot[^1].

The response word count distribution per form topic categorized by partner name:
```{r plot-partner-response-wc, fig.width=10, fig.height=20}
narratives.wc %>%
  gather(variable, value, .responseWordCount) %>% 
  ggplot(aes(labelFormsRecode, value)) +
  geom_boxplot(outlier.colour = "orange", outlier.shape = 1, outlier.alpha = 0.35) +
  coord_flip() +
  geom_jitter(alpha = 0.35) +
  facet_wrap(partnerName ~ ., scales = "free", ncol = 2) +
  labs(
    title = "Word count of responses by form topics per partner",
    subtitle = "A box plot distribution",
    caption = "*Please refer to recode table for label forms"
  ) +
  theme_ecuador1()
```

The response word count distribution per form topic categorized by canton name:
```{r plot-canton-response-wc, fig.width=10, fig.height=20}
narratives.wc %>%
  gather(variable, value, .responseWordCount) %>% 
  ggplot(aes(labelFormsRecode, value)) +
  geom_boxplot(outlier.colour = "orange", outlier.shape = 1, outlier.alpha = 0.35) +
  geom_jitter(alpha = 0.35) +
  coord_flip() +
  facet_wrap(~canton, scales = "free", ncol = 2) +
  labs(
    title = "Word count of responses by form topics per canton",
    subtitle = "A box plot distribution",
    caption = "*Please refer to recode table for label forms"
  ) +
  xlab(NULL) +
  ylab(NULL) +
  theme_ecuador1() +
  theme(panel.spacing = unit(0, "lines"))
```

*A caveat:* Reducing multiple values down to a single value should be avoided in
the early stages of the analysis because reducing hides a lot e.g. a bar chart
showing average the word count per partner. Some partners may write longer than
others, because:

1. They *actually* write longer than other partners.

2. The questions they answered require short answers.

### The "Description" field

Some questions have the description field giving extra details about the
questions.

Do some questions with the extra description field have better *response
quality* than the questions which do not have it?

Looking at the table containing form name, question, description and so on:

```{r, table1}
description.field.wc <- narratives.wc %>% 
  mutate(.hasDescription = ifelse(is.na(description), FALSE, TRUE)) %>% 
  mutate(.descriptionWordCount = word_count(description)) %>%
  select(labelForms, labelFormsRecode, 
         .responseWordCount, .questionWordCount, .descriptionWordCount, 
         .hasDescription)
```

We see in the plot below that the response word counts per form and colored if a
response has a description field or not. Having a description field or not is
calculated as that a description field has a minimum one word.

The responses with the longest word
counts are the ones with description. Nevertheless, it is not so easy to see a
clear trend that there's a correlation between response word count and
description fields. Interestingly, the form *F15*, which is *Protección_VBG*, has
no description fields at all.

```{r, plot1}
description.field.wc.mean <- mean(description.field.wc$.responseWordCount)
description.field.wc %>% 
  ggplot(aes(.responseWordCount, labelFormsRecode, color = .hasDescription)) +
  geom_point() +
  geom_vline(xintercept = description.field.wc.mean, color = "orange", size = 0.6, linetype="dashed") +
  geom_text(
    aes(x = 65, label = "mean", y = 11),
    colour = "orange",
    angle = 90,
    size = 4
  ) +
  labs(
    title = "Word count of responses & description field",
    subtitle = sprintf("Response word count mean: %i", round(description.field.wc.mean))
  )
  theme_ecuador1()
```

We look below the description word count and compare with the
response word count (and remove the categorical field displaying if the question
of response has a description field).

`TODO ANOVA`

### General trends {.tabset}

#### Median word count per partner

```{r}
narratives.wc %>% 
  group_by(partnerName) %>% 
  summarise(median = median(.responseWordCount)) %>% 
  ungroup() %>% 
  ggplot(aes(reorder(partnerName, -median), median)) +
  geom_bar(stat = "identity", width = 0.5, fill = "tomato2") + 
  labs(title = "Median word count of responses per partner",
       subtitle = sprintf("The total median rate %s", round(median(narratives.wc$.responseWordCount), 2))) +
  xlab("Partners") +
  ylab("Median value") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6))
```

#### Median word count of responses

```{r, fig.width=10, fig.height=10}
narratives.med.wc <- narratives %>% 
  mutate(.responseWordCount = word_count(response)) %>%
  mutate(Month = as.Date(paste0(Month, "-01"), format = "%Y-%m-%d")) %>%
  group_by(partnerName, Month) %>%
  summarize(median = median(.responseWordCount)) %>% 
  ungroup()

narratives.med.wc.ts <-
  narratives.med.wc %>%
  mutate(Month = yearmonth(Month)) %>% 
  as_tsibble(index = "Month", key = "partnerName") %>% 
  fill_gaps(median = 0, .full = TRUE)

ggplot(narratives.med.wc.ts, aes(Month, median, color = partnerName)) +
  geom_line() +
  geom_point() +
  labs(title = "Median word count of responses per partner over months",
       subtitle = sprintf("The average median rate %s", round(mean(narratives.med.wc$median), 2))) +
  xlab("Month") +
  ylab("Median word count") +
  scale_x_date(labels = date_format("%Y-%m")) +
  scale_color_brewer(palette = "Paired") +
  facet_wrap(~partnerName, scales = "free", ncol=2) +
  theme_ecuador1() +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

### Correlation

`TODO`

### The regression line

We can look at multiple continuous variables in our data.

- word count of response field: the dependent variable.

- word count of question field: an independent variable.

- word count of description field: an independent variable.

Scatter plots help understand the characteristics of those variables.
However, we miss a general understanding that is the *trend line*.

```{r, plot-linear-regression}
p1 <- description.field.wc %>% 
  ggplot(aes(x = .responseWordCount, y = .questionWordCount)) +
  geom_jitter(alpha = 0.35) +
  geom_smooth(aes(colour = "linear"), method = "lm") +
  theme_ecuador1() +
  theme(legend.position = "none")
p2 <- description.field.wc %>% 
  ggplot(aes(x = .responseWordCount, y = .descriptionWordCount)) +
  geom_jitter(alpha = 0.35) +
  geom_smooth(aes(colour = "linear"), method = "lm") +
  theme_ecuador1() +
  theme(legend.position = "none")
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

The gray area around the lines shows the confidence band at the 0.95 level.
Although there's a straight slope in the linear regression line, we cannot
say that the trend line is robust because the confidence band representing the
uncertainty in the estimate is wide.

### Logistic regression

`TODO`

## Text analysis

In that section, we take text as data.

```{r child = 'analysis/text-analysis.Rmd', eval=FALSE}
```

# References

```{r, echo=FALSE, results='asis'}
bibtex::read.bib("references.bib")
```

